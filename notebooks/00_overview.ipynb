{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“‹ Notebook 00: Pipeline Overview â€” Map of the Journey\n",
        "\n",
        "**Purpose:** Understand the full ML pipeline from raw images to predictions.\n",
        "\n",
        "**Learning Style:** This notebook has no code to write â€” it's your roadmap. Use it to visualize the entire workflow before diving into implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Concept Primer: The Complete Pipeline\n",
        "\n",
        "Medical image classification follows this flow:\n",
        "\n",
        "```\n",
        "Raw Images (96Ã—96 RGB)\n",
        "    â†“\n",
        "Transforms (Resize, Augment, Normalize)\n",
        "    â†“\n",
        "PCamDataset (Custom Dataset class)\n",
        "    â†“\n",
        "DataLoader (Batching & Shuffling)\n",
        "    â†“\n",
        "SimpleCNN Architecture:\n",
        "    Conv2D â†’ ReLU â†’ MaxPool\n",
        "    Conv2D â†’ ReLU â†’ MaxPool\n",
        "    Conv2D â†’ ReLU â†’ MaxPool\n",
        "    Flatten â†’ FC â†’ ReLU â†’ FC â†’ Sigmoid\n",
        "    â†“\n",
        "Binary Cross-Entropy Loss\n",
        "    â†“\n",
        "Adam Optimizer (Backpropagation)\n",
        "    â†“\n",
        "Predictions & Evaluation Metrics\n",
        "```\n",
        "\n",
        "### Key Architectural Choices\n",
        "\n",
        "**Why augment training but not val/test?**\n",
        "- Training: Random flips/rotations create synthetic variety â†’ better generalization\n",
        "- Val/Test: Need consistent, repeatable evaluation â†’ no randomness\n",
        "\n",
        "**Why normalize with mean=std=0.5?**\n",
        "- Converts pixel values from [0,1] â†’ [-1,1]\n",
        "- Centers data around zero â†’ stable gradients during training\n",
        "- Must be **identical** across train/val/test\n",
        "\n",
        "**Why Sigmoid for binary classification?**\n",
        "- Outputs a probability in [0,1]\n",
        "- Pairs with `BCELoss` (Binary Cross-Entropy Loss)\n",
        "- Alternative: `BCEWithLogitsLoss` + no Sigmoid (more numerically stable, but we use Sigmoid here for interpretability)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Learning Objectives\n",
        "\n",
        "By the end of this project, you will:\n",
        "\n",
        "1. âœ… Understand why data augmentation improves generalization\n",
        "2. âœ… Build a custom PyTorch `Dataset` class (provided as `PCamDataset`)\n",
        "3. âœ… Implement `DataLoader` with proper batching and shuffling\n",
        "4. âœ… Design a simple CNN with 3 convolutional blocks\n",
        "5. âœ… Train a model with train/validation splits\n",
        "6. âœ… Evaluate performance with precision, recall, and F1-score\n",
        "7. âœ… Reflect on clinical implications of false positives vs false negatives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Acceptance Criteria\n",
        "\n",
        "You understand the pipeline when you can:\n",
        "\n",
        "- [ ] Narrate the flow from images â†’ predictions in 60â€“90 seconds\n",
        "- [ ] Explain why train transforms differ from val/test transforms\n",
        "- [ ] Describe what each layer in the CNN does (Conv, Pool, FC)\n",
        "- [ ] Justify why we use Sigmoid + BCELoss vs alternatives\n",
        "- [ ] Articulate the difference between training loss and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ—ï¸ Architecture Deep Dive\n",
        "\n",
        "### SimpleCNN Architecture\n",
        "\n",
        "```python\n",
        "Input: [Batch, 3, 96, 96]\n",
        "    â†“\n",
        "Conv1: [Batch, 32, 96, 96]  (3â†’32 channels, kernel=3, padding=1)\n",
        "ReLU + MaxPool(2Ã—2)\n",
        "    â†“\n",
        "[Batch, 32, 48, 48]\n",
        "    â†“\n",
        "Conv2: [Batch, 64, 48, 48]  (32â†’64 channels)\n",
        "ReLU + MaxPool(2Ã—2)\n",
        "    â†“\n",
        "[Batch, 64, 24, 24]\n",
        "    â†“\n",
        "Conv3: [Batch, 128, 24, 24]  (64â†’128 channels)\n",
        "ReLU + MaxPool(2Ã—2)\n",
        "    â†“\n",
        "[Batch, 128, 12, 12]\n",
        "    â†“\n",
        "Flatten: [Batch, 18432]  (128 Ã— 12 Ã— 12 = 18,432)\n",
        "    â†“\n",
        "FC1: [Batch, 256]\n",
        "ReLU\n",
        "    â†“\n",
        "FC2: [Batch, 1]\n",
        "Sigmoid\n",
        "    â†“\n",
        "Output: [Batch]  (probabilities in [0,1])\n",
        "```\n",
        "\n",
        "### Spatial Dimension Math\n",
        "\n",
        "- **Start:** 96Ã—96\n",
        "- **After 1st pool:** 96 Ã· 2 = 48Ã—48\n",
        "- **After 2nd pool:** 48 Ã· 2 = 24Ã—24\n",
        "- **After 3rd pool:** 24 Ã· 2 = 12Ã—12\n",
        "\n",
        "**Why three pooling layers?**\n",
        "- Progressively reduces spatial dimensions while increasing feature channels\n",
        "- Final 12Ã—12 is small enough for FC layers but preserves spatial information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¤” Reflection Prompt\n",
        "\n",
        "**Write a one-paragraph \"model card\" for this CNN:**\n",
        "\n",
        "Consider:\n",
        "- **Intended Use:** What is this model designed to do? (e.g., \"Educational tool for binary tumor classification on PCam patches\")\n",
        "- **Limitations:** What can it NOT do? (e.g., \"Not validated for clinical use; trained on limited subset\")\n",
        "- **Potential Misuse:** How could someone misuse it? (e.g., \"Using predictions for patient diagnosis without physician oversight\")\n",
        "- **Ethical Considerations:** What are the clinical consequences of errors?\n",
        "\n",
        "**Write your model card here (in your own words):**\n",
        "\n",
        "---\n",
        "\n",
        "*(Example structure:)*\n",
        "> This model is an educational CNN trained on PatchCamelyon data to classify 96Ã—96 histopathology patches as Normal (0) or Tumor (1). It is intended solely for learning PyTorch and medical image classification concepts. **Limitations:** The model is trained on a small subset, lacks external validation, and achieves [X]% accuracy on the test set. It should never be used for clinical decisions. **Ethical risks:** False negatives (missed tumors) could delay cancer treatment, while false positives cause unnecessary biopsies and patient anxiety. This model serves as a starting point for understanding medical AI, not as a deployable solution.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Next Steps\n",
        "\n",
        "Move to **Notebook 01: Train Transforms** to start building your data pipeline!\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Reference: Variable Names Used Throughout**\n",
        "\n",
        "| Variable | Purpose |\n",
        "|----------|---------|\n",
        "| `train_transform` | Augmentation pipeline for training |\n",
        "| `val_test_transform` | Deterministic pipeline for val/test |\n",
        "| `train_dataset`, `val_dataset`, `test_dataset` | PCamDataset instances |\n",
        "| `train_dataloader`, `val_dataloader`, `test_dataloader` | DataLoader instances |\n",
        "| `cnn_model` | SimpleCNN instance |\n",
        "| `device` | torch.device (cuda/cpu) |\n",
        "| `criterion` | BCELoss instance |\n",
        "| `optimizer` | Adam optimizer |\n",
        "| `train_losses`, `val_losses` | Lists tracking loss per epoch |\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
