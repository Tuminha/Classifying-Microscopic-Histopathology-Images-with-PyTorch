{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📋 Notebook 00: Pipeline Overview — Map of the Journey\n",
        "\n",
        "**Purpose:** Understand the full ML pipeline from raw images to predictions.\n",
        "\n",
        "**Learning Style:** This notebook has no code to write — it's your roadmap. Use it to visualize the entire workflow before diving into implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Concept Primer: The Complete Pipeline\n",
        "\n",
        "Medical image classification follows this flow:\n",
        "\n",
        "```\n",
        "Raw Images (96×96 RGB)\n",
        "    ↓\n",
        "Transforms (Resize, Augment, Normalize)\n",
        "    ↓\n",
        "PCamDataset (Custom Dataset class)\n",
        "    ↓\n",
        "DataLoader (Batching & Shuffling)\n",
        "    ↓\n",
        "SimpleCNN Architecture:\n",
        "    Conv2D → ReLU → MaxPool\n",
        "    Conv2D → ReLU → MaxPool\n",
        "    Conv2D → ReLU → MaxPool\n",
        "    Flatten → FC → ReLU → FC → Sigmoid\n",
        "    ↓\n",
        "Binary Cross-Entropy Loss\n",
        "    ↓\n",
        "Adam Optimizer (Backpropagation)\n",
        "    ↓\n",
        "Predictions & Evaluation Metrics\n",
        "```\n",
        "\n",
        "### Key Architectural Choices\n",
        "\n",
        "**Why augment training but not val/test?**\n",
        "- Training: Random flips/rotations create synthetic variety → better generalization\n",
        "- Val/Test: Need consistent, repeatable evaluation → no randomness\n",
        "\n",
        "**Why normalize with mean=std=0.5?**\n",
        "- Converts pixel values from [0,1] → [-1,1]\n",
        "- Centers data around zero → stable gradients during training\n",
        "- Must be **identical** across train/val/test\n",
        "\n",
        "**Why Sigmoid for binary classification?**\n",
        "- Outputs a probability in [0,1]\n",
        "- Pairs with `BCELoss` (Binary Cross-Entropy Loss)\n",
        "- Alternative: `BCEWithLogitsLoss` + no Sigmoid (more numerically stable, but we use Sigmoid here for interpretability)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 Learning Objectives\n",
        "\n",
        "By the end of this project, you will:\n",
        "\n",
        "1. ✅ Understand why data augmentation improves generalization\n",
        "2. ✅ Build a custom PyTorch `Dataset` class (provided as `PCamDataset`)\n",
        "3. ✅ Implement `DataLoader` with proper batching and shuffling\n",
        "4. ✅ Design a simple CNN with 3 convolutional blocks\n",
        "5. ✅ Train a model with train/validation splits\n",
        "6. ✅ Evaluate performance with precision, recall, and F1-score\n",
        "7. ✅ Reflect on clinical implications of false positives vs false negatives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ Acceptance Criteria\n",
        "\n",
        "You understand the pipeline when you can:\n",
        "\n",
        "- [ ] Narrate the flow from images → predictions in 60–90 seconds\n",
        "- [ ] Explain why train transforms differ from val/test transforms\n",
        "- [ ] Describe what each layer in the CNN does (Conv, Pool, FC)\n",
        "- [ ] Justify why we use Sigmoid + BCELoss vs alternatives\n",
        "- [ ] Articulate the difference between training loss and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ Architecture Deep Dive\n",
        "\n",
        "### SimpleCNN Architecture\n",
        "\n",
        "```python\n",
        "Input: [Batch, 3, 96, 96]\n",
        "    ↓\n",
        "Conv1: [Batch, 32, 96, 96]  (3→32 channels, kernel=3, padding=1)\n",
        "ReLU + MaxPool(2×2)\n",
        "    ↓\n",
        "[Batch, 32, 48, 48]\n",
        "    ↓\n",
        "Conv2: [Batch, 64, 48, 48]  (32→64 channels)\n",
        "ReLU + MaxPool(2×2)\n",
        "    ↓\n",
        "[Batch, 64, 24, 24]\n",
        "    ↓\n",
        "Conv3: [Batch, 128, 24, 24]  (64→128 channels)\n",
        "ReLU + MaxPool(2×2)\n",
        "    ↓\n",
        "[Batch, 128, 12, 12]\n",
        "    ↓\n",
        "Flatten: [Batch, 18432]  (128 × 12 × 12 = 18,432)\n",
        "    ↓\n",
        "FC1: [Batch, 256]\n",
        "ReLU\n",
        "    ↓\n",
        "FC2: [Batch, 1]\n",
        "Sigmoid\n",
        "    ↓\n",
        "Output: [Batch]  (probabilities in [0,1])\n",
        "```\n",
        "\n",
        "### Spatial Dimension Math\n",
        "\n",
        "- **Start:** 96×96\n",
        "- **After 1st pool:** 96 ÷ 2 = 48×48\n",
        "- **After 2nd pool:** 48 ÷ 2 = 24×24\n",
        "- **After 3rd pool:** 24 ÷ 2 = 12×12\n",
        "\n",
        "**Why three pooling layers?**\n",
        "- Progressively reduces spatial dimensions while increasing feature channels\n",
        "- Final 12×12 is small enough for FC layers but preserves spatial information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Reflection Prompt\n",
        "\n",
        "**Write a one-paragraph \"model card\" for this CNN:**\n",
        "\n",
        "Consider:\n",
        "- **Intended Use:** What is this model designed to do? (e.g., \"Educational tool for binary tumor classification on PCam patches\")\n",
        "- **Limitations:** What can it NOT do? (e.g., \"Not validated for clinical use; trained on limited subset\")\n",
        "- **Potential Misuse:** How could someone misuse it? (e.g., \"Using predictions for patient diagnosis without physician oversight\")\n",
        "- **Ethical Considerations:** What are the clinical consequences of errors?\n",
        "\n",
        "**Write your model card here (in your own words):**\n",
        "\n",
        "---\n",
        "\n",
        "*(Example structure:)*\n",
        "> This model is an educational CNN trained on PatchCamelyon data to classify 96×96 histopathology patches as Normal (0) or Tumor (1). It is intended solely for learning PyTorch and medical image classification concepts. **Limitations:** The model is trained on a small subset, lacks external validation, and achieves [X]% accuracy on the test set. It should never be used for clinical decisions. **Ethical risks:** False negatives (missed tumors) could delay cancer treatment, while false positives cause unnecessary biopsies and patient anxiety. This model serves as a starting point for understanding medical AI, not as a deployable solution.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Next Steps\n",
        "\n",
        "Move to **Notebook 01: Train Transforms** to start building your data pipeline!\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Reference: Variable Names Used Throughout**\n",
        "\n",
        "| Variable | Purpose |\n",
        "|----------|---------|\n",
        "| `train_transform` | Augmentation pipeline for training |\n",
        "| `val_test_transform` | Deterministic pipeline for val/test |\n",
        "| `train_dataset`, `val_dataset`, `test_dataset` | PCamDataset instances |\n",
        "| `train_dataloader`, `val_dataloader`, `test_dataloader` | DataLoader instances |\n",
        "| `cnn_model` | SimpleCNN instance |\n",
        "| `device` | torch.device (cuda/cpu) |\n",
        "| `criterion` | BCELoss instance |\n",
        "| `optimizer` | Adam optimizer |\n",
        "| `train_losses`, `val_losses` | Lists tracking loss per epoch |\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
