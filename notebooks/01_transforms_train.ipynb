{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Notebook 01: Train Transforms â€” Data Augmentation Pipeline\n",
    "\n",
    "**Purpose:** Build a robust augmentation pipeline for training data to improve model generalization.\n",
    "\n",
    "**What you'll learn:** How to compose transforms in the correct order, why augmentation matters, and how normalization stabilizes training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Concept Primer: Why Data Augmentation?\n",
    "\n",
    "### The Problem: Limited Data\n",
    "- Deep learning models need **thousands** of examples to generalize well\n",
    "- Medical imaging datasets are expensive to label (expert pathologists needed)\n",
    "- Small datasets â†’ **overfitting** (model memorizes training examples)\n",
    "\n",
    "### The Solution: Data Augmentation\n",
    "- Create **synthetic variety** by applying realistic transformations\n",
    "- Horizontal flips, rotations, color jitter â†’ model learns invariant features\n",
    "- **Only applied to training data** (val/test need consistency)\n",
    "\n",
    "### Transform Order Matters!\n",
    "```\n",
    "âœ… CORRECT:\n",
    "Resize â†’ Augmentation (Flip, Rotate, ColorJitter) â†’ ToTensor â†’ Normalize\n",
    "\n",
    "âŒ WRONG:\n",
    "ToTensor â†’ ColorJitter  (ColorJitter expects PIL images, not tensors!)\n",
    "Normalize â†’ Resize  (Normalize expects [0,1] tensor values)\n",
    "```\n",
    "\n",
    "### Normalization Deep Dive\n",
    "- `ToTensor()` converts PIL image [0,255] â†’ tensor [0,1]\n",
    "- `Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])` converts [0,1] â†’ [-1,1]\n",
    "- **Formula:** `output = (input - mean) / std`\n",
    "- **Why?** Centered data â†’ stable gradients â†’ faster convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. âœ… Build `train_transform` with `transforms.Compose()`\n",
    "2. âœ… Apply augmentations in the correct order\n",
    "3. âœ… Understand which augmentations are realistic for histopathology\n",
    "4. âœ… Normalize images to stabilize training\n",
    "5. âœ… Verify transform output shape: `[3, 96, 96]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Acceptance Criteria\n",
    "\n",
    "Your transform pipeline is correct when:\n",
    "\n",
    "- [ ] `train_transform` is a `transforms.Compose` object\n",
    "- [ ] Transforms are in order: Resize â†’ RandomHorizontalFlip â†’ RandomRotation â†’ ColorJitter â†’ ToTensor â†’ Normalize\n",
    "- [ ] Applying transform to a sample image produces a tensor of shape `[3, 96, 96]`\n",
    "- [ ] Tensor values are in range `[-1, 1]` (after normalization)\n",
    "- [ ] You can explain why ColorJitter comes **before** ToTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’» TODO 1: Import Required Libraries\n",
    "\n",
    "**What you need:**\n",
    "- `torchvision.transforms` for transform classes\n",
    "- `PIL.Image` to test loading a sample image\n",
    "\n",
    "**Expected behavior:** Imports run without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Import transforms and Image\n",
    "# Hint: from torchvision import transforms\n",
    "# Hint: from PIL import Image\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’» TODO 2: Build the Training Transform Pipeline\n",
    "\n",
    "**What you need to compose (in this order):**\n",
    "\n",
    "1. **`transforms.Resize((96, 96))`** â€” Ensure all images are 96Ã—96\n",
    "2. **`transforms.RandomHorizontalFlip(p=0.5)`** â€” Flip left-right 50% of the time\n",
    "3. **`transforms.RandomRotation(degrees=15)`** â€” Rotate Â±15Â° randomly\n",
    "4. **`transforms.ColorJitter(brightness=0.2, contrast=0.2)`** â€” Vary brightness/contrast\n",
    "5. **`transforms.ToTensor()`** â€” Convert PIL image â†’ tensor [0,1]\n",
    "6. **`transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])`** â€” Normalize to [-1,1]\n",
    "\n",
    "**Expected output:** A `transforms.Compose` object stored in `train_transform`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_transform created:\n",
      "Compose(\n",
      "    Resize(size=(96, 96), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO 2: Create train_transform using transforms.Compose()\n",
    "# Hint: train_transform = transforms.Compose([...])\n",
    "# Hint: List the 6 transforms above in the correct order\n",
    "\n",
    "# YOUR CODE HERE\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])  \n",
    "\n",
    "print(\"âœ… train_transform created:\")\n",
    "print(train_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’» TODO 3: Test the Transform on a Sample Image\n",
    "\n",
    "**What you need to do:**\n",
    "1. Load a sample image from `../data/pcam_images/` (pick any `.png` file)\n",
    "2. Apply `train_transform` to the image\n",
    "3. Print the shape of the resulting tensor\n",
    "\n",
    "**Expected output:**\n",
    "```\n",
    "Original image: PIL Image object\n",
    "Transformed tensor shape: torch.Size([3, 96, 96])\n",
    "Tensor value range: approximately [-1, 1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 96, 96])\n",
      "First value of shape refers to the number of channels and in this case is: 3\n",
      "Second and third values refer to the height and width of the image and in this case are: 96 and 96\n",
      "The value range is: tensor(-0.8196) and tensor(1.)\n",
      "âœ… Sample image path: ../data/pcam_images/348.png\n"
     ]
    }
   ],
   "source": [
    "# TODO 3: Test transform on a sample image\n",
    "# Hint: sample_img = Image.open('../data/pcam_images/SOME_FILE.png')\n",
    "# Hint: transformed = train_transform(sample_img)\n",
    "# Hint: print(transformed.shape)\n",
    "\n",
    "import os\n",
    "\n",
    "# Get a sample image path\n",
    "sample_images = os.listdir('../data/pcam_images/')\n",
    "sample_path = os.path.join('../data/pcam_images/', sample_images[0])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Load the image\n",
    "with Image.open(sample_path) as sample_img:\n",
    "    transformed = train_transform(sample_img)\n",
    "# Apply train_transform\n",
    "    train_transform\n",
    "# Print the shape and value range\n",
    "    print(transformed.shape)\n",
    "    print(\"First value of shape refers to the number of channels and in this case is:\", transformed.shape[0])\n",
    "    print(\"Second and third values refer to the height and width of the image and in this case are:\", transformed.shape[1], \"and\", transformed.shape[2])\n",
    "    print(\"The value range is:\", transformed.min(), \"and\", transformed.max())\n",
    "print(f\"âœ… Sample image path: {sample_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ¤” Reflection Prompts\n",
    "\n",
    "### Question 1: Realistic Augmentations for Histopathology\n",
    "Which of the following augmentations are **realistic** for H&E-stained pathology slides, and which might **distort clinically relevant information**?\n",
    "\n",
    "| Augmentation | Realistic? | Reasoning |\n",
    "|--------------|------------|-----------|\n",
    "| RandomHorizontalFlip | âœ… / âŒ | ? |\n",
    "| RandomVerticalFlip | âœ… / âŒ | ? |\n",
    "| RandomRotation(Â±15Â°) | âœ… / âŒ | ? |\n",
    "| RandomRotation(Â±180Â°) | âœ… / âŒ | ? |\n",
    "| ColorJitter(brightness=0.2) | âœ… / âŒ | ? |\n",
    "| ColorJitter(hue=0.5) | âœ… / âŒ | ? |\n",
    "| RandomGrayscale | âœ… / âŒ | ? |\n",
    "\n",
    "**Your analysis:**\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2: Why Not Augment Validation/Test Data?\n",
    "Explain in your own words:\n",
    "- Why do we apply augmentation to training data?\n",
    "- Why would augmentation **break** validation/test evaluation?\n",
    "\n",
    "**Your explanation:**\n",
    "> We augment training data to teach the model to handle natural variations (orientation, lighting, color shifts), preventing it from memorizing specific training examples. This helps generalization.\n",
    ">\n",
    "> We DON'T augment validation/test because we need **consistent, reproducible evaluation**. Each validation/test image should be processed the same way every time, so we can accurately measure model performance and track improvements.\n",
    ">\n",
    "> If we augmented validation data randomly each time, we'd get different results each runâ€”making it impossible to know if the model improved or if we just got \"lucky\" augmented images that round!\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3: Normalization Intuition\n",
    "Given:\n",
    "- `ToTensor()` converts RGB [0,255] â†’ [0,1]\n",
    "- `Normalize(mean=[0.5]*3, std=[0.5]*3)` converts [0,1] â†’ [-1,1]\n",
    "\n",
    "Calculate:\n",
    "- If a pixel value is `0.8` after `ToTensor()`, what is it after `Normalize`?\n",
    "- **Formula:** `(input - mean) / std`\n",
    "\n",
    "**Your calculation:**\n",
    "> Using the formula: `output = (input - mean) / std`\n",
    "> \n",
    "> `output = (0.8 - 0.5) / 0.5`\n",
    "> `output = 0.3 / 0.5`\n",
    "> `output = 0.6`\n",
    ">\n",
    "> So a pixel value of `0.8` becomes `0.6` after normalization!\n",
    ">\n",
    "> **Visual meaning:** The pixel stays bright (80% â†’ 60% of max), but now it's centered around 0 instead of 0.5. This helps stabilize training by keeping gradients centered.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Next Steps\n",
    "\n",
    "Great work! You've built a training transform pipeline with augmentation.\n",
    "\n",
    "**Move to Notebook 02:** Train Dataset & DataLoader\n",
    "\n",
    "**Key Takeaway:** Transform order matters â€” Resize/Aug â†’ ToTensor â†’ Normalize!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codecademy ML",
   "language": "python",
   "name": "codeacademy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
