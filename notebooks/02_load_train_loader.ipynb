{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“¦ Notebook 02: Train Dataset & DataLoader\n",
        "\n",
        "**Purpose:** Instantiate the training dataset and DataLoader to batch and shuffle data efficiently.\n",
        "\n",
        "**What you'll learn:** How PyTorch's `Dataset` and `DataLoader` work together, why we shuffle training data, and how batching improves training efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Concept Primer: Dataset & DataLoader\n",
        "\n",
        "### The Dataset Class\n",
        "- **Custom `Dataset`** reads image paths from a CSV and applies transforms\n",
        "- Must implement:\n",
        "  - `__len__()` â†’ returns total number of samples\n",
        "  - `__getitem__(idx)` â†’ returns (image, label) for a given index\n",
        "- **Provided:** `PCamDataset` is already implemented in `src/datasets/pcam_dataset.py`\n",
        "\n",
        "### The DataLoader\n",
        "- **Batches** data: Instead of processing 1 image at a time, process N images together\n",
        "- **Shuffles** training data: Randomizes order each epoch â†’ prevents overfitting to sequence\n",
        "- **Parallelizes** loading: `num_workers` loads data in background (optional)\n",
        "\n",
        "### Why Shuffle Training Data?\n",
        "- **Without shuffle:** Model might learn spurious patterns from data order\n",
        "- **With shuffle:** Each epoch sees data in different order â†’ better generalization\n",
        "- **Val/Test:** NO shuffle (need consistent, repeatable evaluation)\n",
        "\n",
        "### Batch Size Trade-offs\n",
        "| Batch Size | GPU Memory | Training Speed | Gradient Noise |\n",
        "|------------|------------|----------------|----------------|\n",
        "| Small (8) | Low | Slower | High (more updates) |\n",
        "| Large (32+) | High | Faster | Low (fewer updates) |\n",
        "\n",
        "**For training:** Small batches (8-16) often generalize better\n",
        "**For evaluation:** Large batches (32-64) for speed (no backprop needed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. âœ… Import the provided `PCamDataset` class\n",
        "2. âœ… Instantiate `train_dataset` with the training CSV and `train_transform`\n",
        "3. âœ… Create `train_dataloader` with `batch_size=8` and `shuffle=True`\n",
        "4. âœ… Iterate one batch and verify shapes: `images=[8,3,96,96]`, `labels=[8]`\n",
        "5. âœ… Understand why we shuffle training data but not validation/test data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Acceptance Criteria\n",
        "\n",
        "Your dataset and dataloader are correct when:\n",
        "\n",
        "- [ ] `train_dataset` is an instance of `PCamDataset`\n",
        "- [ ] `len(train_dataset)` returns the number of training samples\n",
        "- [ ] `train_dataloader` is a `DataLoader` with `shuffle=True`\n",
        "- [ ] Iterating one batch produces:\n",
        "  - `images.shape = torch.Size([8, 3, 96, 96])`\n",
        "  - `labels.shape = torch.Size([8])`\n",
        "  - `labels` contain only 0s and 1s (Normal/Tumor)\n",
        "- [ ] You can explain why shuffling matters for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 1: Import Required Libraries & Load train_transform\n",
        "\n",
        "**What you need:**\n",
        "- `torch` and `torch.utils.data.DataLoader`\n",
        "- `PCamDataset` from `src.datasets.pcam_dataset`\n",
        "- The `train_transform` you built in Notebook 01 (rebuild it here)\n",
        "\n",
        "**Expected behavior:** Imports run without errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 1: Import libraries and rebuild train_transform\n",
        "# Hint: import torch\n",
        "# Hint: from torch.utils.data import DataLoader\n",
        "# Hint: from torchvision import transforms\n",
        "# Hint: from src.datasets.pcam_dataset import PCamDataset\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Rebuild train_transform (copy from Notebook 01)\n",
        "train_transform = None  # Replace with transforms.Compose([...])\n",
        "\n",
        "print(\"âœ… Imports successful and train_transform ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 2: Instantiate the Training Dataset\n",
        "\n",
        "**What you need to do:**\n",
        "```python\n",
        "train_dataset = PCamDataset(\n",
        "    csv_file='../data/train_labels.csv',\n",
        "    transform=train_transform\n",
        ")\n",
        "```\n",
        "\n",
        "**Expected output:** \n",
        "- `train_dataset` is a `PCamDataset` object\n",
        "- `len(train_dataset)` prints the number of training samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2: Create train_dataset\n",
        "# Hint: train_dataset = PCamDataset(csv_file='...', transform=train_transform)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "train_dataset = None  # Replace this line\n",
        "\n",
        "print(f\"âœ… Training dataset created\")\n",
        "print(f\"   Total training samples: {len(train_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 3: Create the Training DataLoader\n",
        "\n",
        "**What you need to do:**\n",
        "```python\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0  # Use 0 for compatibility, or 2-4 for faster loading\n",
        ")\n",
        "```\n",
        "\n",
        "**Key parameters:**\n",
        "- `batch_size=8` â†’ Process 8 images per batch\n",
        "- `shuffle=True` â†’ Randomize order each epoch\n",
        "- `num_workers=0` â†’ No parallel loading (safe default)\n",
        "\n",
        "**Expected output:** `train_dataloader` is a `DataLoader` object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3: Create train_dataloader\n",
        "# Hint: train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "train_dataloader = None  # Replace this line\n",
        "\n",
        "print(f\"âœ… Training DataLoader created\")\n",
        "print(f\"   Batch size: 8\")\n",
        "print(f\"   Number of batches: {len(train_dataloader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 4: Test the DataLoader â€” Iterate One Batch\n",
        "\n",
        "**What you need to do:**\n",
        "1. Get one batch from `train_dataloader` using a `for` loop (break after first batch)\n",
        "2. Print the shapes of `images` and `labels`\n",
        "3. Print the unique label values to verify 0s and 1s\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "âœ… First batch loaded\n",
        "   Images shape: torch.Size([8, 3, 96, 96])\n",
        "   Labels shape: torch.Size([8])\n",
        "   Unique labels: tensor([0, 1])  (or just [0] or [1] depending on batch)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4: Iterate one batch and verify shapes\n",
        "# Hint: for images, labels in train_dataloader:\n",
        "#           print(images.shape)\n",
        "#           break\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "print(\"âœ… First batch loaded\")\n",
        "# Print images.shape, labels.shape, torch.unique(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤” Reflection Prompts\n",
        "\n",
        "### Question 1: Why Shuffle Training Data?\n",
        "Imagine your training CSV is sorted: first 500 samples are Normal (0), next 500 are Tumor (1).\n",
        "\n",
        "**Scenario A:** `shuffle=False`\n",
        "- What pattern might the model learn in the first few batches?\n",
        "- Why is this a problem?\n",
        "\n",
        "**Scenario B:** `shuffle=True`\n",
        "- How does this fix the problem?\n",
        "\n",
        "**Your explanation:**\n",
        "\n",
        "---\n",
        "\n",
        "### Question 2: Batch Size Impact\n",
        "Compare these two setups:\n",
        "\n",
        "| Setup | Batch Size | Batches per Epoch | Updates per Epoch |\n",
        "|-------|------------|-------------------|-------------------|\n",
        "| A | 8 | 125 (1000/8) | 125 |\n",
        "| B | 32 | 32 (1000/32) | 32 |\n",
        "\n",
        "Assuming 1000 training samples:\n",
        "- Which setup makes **more gradient updates** per epoch?\n",
        "- Which setup is **faster** (fewer iterations)?\n",
        "- Which might **generalize better** (more noisy gradients)?\n",
        "\n",
        "**Your analysis:**\n",
        "\n",
        "---\n",
        "\n",
        "### Question 3: num_workers Mystery\n",
        "The `num_workers` parameter controls parallel data loading.\n",
        "\n",
        "- `num_workers=0`: Data loads in main process (slower, but no issues)\n",
        "- `num_workers=4`: Data loads in 4 parallel workers (faster, but can cause bugs)\n",
        "\n",
        "When might you set `num_workers > 0`?  \n",
        "When might you stick with `num_workers=0`?\n",
        "\n",
        "**Your answer:**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Next Steps\n",
        "\n",
        "Excellent! You've loaded training data with batching and shuffling.\n",
        "\n",
        "**Move to Notebook 03:** Val/Test Transforms (No Augmentation)\n",
        "\n",
        "**Key Takeaway:** Training DataLoader shuffles; validation/test do NOT!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
