{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“¦ Notebook 02: Train Dataset & DataLoader\n",
        "\n",
        "**Purpose:** Instantiate the training dataset and DataLoader to batch and shuffle data efficiently.\n",
        "\n",
        "**What you'll learn:** How PyTorch's `Dataset` and `DataLoader` work together, why we shuffle training data, and how batching improves training efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Concept Primer: Dataset & DataLoader\n",
        "\n",
        "### The Dataset Class\n",
        "- **Custom `Dataset`** reads image paths from a CSV and applies transforms\n",
        "- Must implement:\n",
        "  - `__len__()` â†’ returns total number of samples\n",
        "  - `__getitem__(idx)` â†’ returns (image, label) for a given index\n",
        "- **Provided:** `PCamDataset` is already implemented in `src/datasets/pcam_dataset.py`\n",
        "\n",
        "### The DataLoader\n",
        "- **Batches** data: Instead of processing 1 image at a time, process N images together\n",
        "- **Shuffles** training data: Randomizes order each epoch â†’ prevents overfitting to sequence\n",
        "- **Parallelizes** loading: `num_workers` loads data in background (optional)\n",
        "\n",
        "### Why Shuffle Training Data?\n",
        "- **Without shuffle:** Model might learn spurious patterns from data order\n",
        "- **With shuffle:** Each epoch sees data in different order â†’ better generalization\n",
        "- **Val/Test:** NO shuffle (need consistent, repeatable evaluation)\n",
        "\n",
        "### Batch Size Trade-offs\n",
        "| Batch Size | GPU Memory | Training Speed | Gradient Noise |\n",
        "|------------|------------|----------------|----------------|\n",
        "| Small (8) | Low | Slower | High (more updates) |\n",
        "| Large (32+) | High | Faster | Low (fewer updates) |\n",
        "\n",
        "**For training:** Small batches (8-16) often generalize better\n",
        "**For evaluation:** Large batches (32-64) for speed (no backprop needed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. âœ… Import the provided `PCamDataset` class\n",
        "2. âœ… Instantiate `train_dataset` with the training CSV and `train_transform`\n",
        "3. âœ… Create `train_dataloader` with `batch_size=8` and `shuffle=True`\n",
        "4. âœ… Iterate one batch and verify shapes: `images=[8,3,96,96]`, `labels=[8]`\n",
        "5. âœ… Understand why we shuffle training data but not validation/test data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Acceptance Criteria\n",
        "\n",
        "Your dataset and dataloader are correct when:\n",
        "\n",
        "- [ ] `train_dataset` is an instance of `PCamDataset`\n",
        "- [ ] `len(train_dataset)` returns the number of training samples\n",
        "- [ ] `train_dataloader` is a `DataLoader` with `shuffle=True`\n",
        "- [ ] Iterating one batch produces:\n",
        "  - `images.shape = torch.Size([8, 3, 96, 96])`\n",
        "  - `labels.shape = torch.Size([8])`\n",
        "  - `labels` contain only 0s and 1s (Normal/Tumor)\n",
        "- [ ] You can explain why shuffling matters for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 1: Import Required Libraries & Load train_transform\n",
        "\n",
        "**What you need:**\n",
        "- `torch` and `torch.utils.data.DataLoader`\n",
        "- `PCamDataset` from `src.datasets.pcam_dataset`\n",
        "- The `train_transform` you built in Notebook 01 (rebuild it here)\n",
        "\n",
        "**Expected behavior:** Imports run without errors.\n",
        "\n",
        "**âš ï¸ IMPORTANT:** If you get a ValueError about 'image_id' vs 'filename', the code was updated but Python hasn't reloaded the module. Do this:\n",
        "1. **Restart the kernel** (Kernel â†’ Restart) to reload all modules\n",
        "2. Or run this in a code cell before the imports:\n",
        "   ```python\n",
        "   import importlib\n",
        "   import sys\n",
        "   if 'src.datasets.pcam_dataset' in sys.modules:\n",
        "       importlib.reload(sys.modules['src.datasets.pcam_dataset'])\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Imports successful and train_transform ready\n"
          ]
        }
      ],
      "source": [
        "# TODO 1: Import libraries and rebuild train_transform\n",
        "# Hint: import torch\n",
        "# Hint: from torch.utils.data import DataLoader\n",
        "# Hint: from torchvision import transforms\n",
        "# Hint: from src.datasets.pcam_dataset import PCamDataset\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from src.datasets.pcam_dataset import PCamDataset\n",
        "# Rebuild train_transform (copy from Notebook 01)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])  \n",
        "\n",
        "\n",
        "print(\"âœ… Imports successful and train_transform ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 2: Instantiate the Training Dataset\n",
        "\n",
        "**What you need to do:**\n",
        "```python\n",
        "train_dataset = PCamDataset(\n",
        "    csv_file='../data/train_labels.csv',\n",
        "    transform=train_transform\n",
        ")\n",
        "```\n",
        "\n",
        "**Expected output:** \n",
        "- `train_dataset` is a `PCamDataset` object\n",
        "- `len(train_dataset)` prints the number of training samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training dataset created\n",
            "   Total training samples: 600\n"
          ]
        }
      ],
      "source": [
        "# TODO 2: Create train_dataset\n",
        "# Hint: train_dataset = PCamDataset(csv_file='...', transform=train_transform)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "train_dataset = PCamDataset(\n",
        "    csv_file = \"../data/train_labels.csv\",\n",
        "    transform = train_transform\n",
        ")  \n",
        "\n",
        "print(f\"âœ… Training dataset created\")\n",
        "print(f\"   Total training samples: {len(train_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 3: Create the Training DataLoader\n",
        "\n",
        "**What you need to do:**\n",
        "```python\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0  # Use 0 for compatibility, or 2-4 for faster loading\n",
        ")\n",
        "```\n",
        "\n",
        "**Key parameters:**\n",
        "- `batch_size=8` â†’ Process 8 images per batch\n",
        "- `shuffle=True` â†’ Randomize order each epoch\n",
        "- `num_workers=0` â†’ No parallel loading (safe default)\n",
        "\n",
        "**Expected output:** `train_dataloader` is a `DataLoader` object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training DataLoader created\n",
            "   Batch size: 8\n",
            "   Number of batches: 75\n"
          ]
        }
      ],
      "source": [
        "# TODO 3: Create train_dataloader\n",
        "# Hint: train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")  \n",
        "\n",
        "print(f\"âœ… Training DataLoader created\")\n",
        "print(f\"   Batch size: 8\")\n",
        "print(f\"   Number of batches: {len(train_dataloader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ’» TODO 4: Test the DataLoader â€” Iterate One Batch\n",
        "\n",
        "**What you need to do:**\n",
        "1. Get one batch from `train_dataloader` using a `for` loop (break after first batch)\n",
        "2. Print the shapes of `images` and `labels`\n",
        "3. Print the unique label values to verify 0s and 1s\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "âœ… First batch loaded\n",
        "   Images shape: torch.Size([8, 3, 96, 96])\n",
        "   Labels shape: torch.Size([8])\n",
        "   Unique labels: tensor([0, 1])  (or just [0] or [1] depending on batch)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… First batch loaded\n",
            "   Images shape: torch.Size([8, 3, 96, 96])\n",
            "   Labels shape: torch.Size([8])\n",
            "   Unique labels: tensor([0, 1])\n",
            "âœ… First batch loaded\n"
          ]
        }
      ],
      "source": [
        "# TODO 4: Iterate one batch and verify shapes\n",
        "# Hint: for images, labels in train_dataloader:\n",
        "#           print(images.shape)\n",
        "#           break\n",
        "\n",
        "# YOUR CODE HERE\n",
        "import torch\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    images, labels = batch\n",
        "    print(\"âœ… First batch loaded\")\n",
        "    print(f\"   Images shape: {images.shape}\")\n",
        "    print(f\"   Labels shape: {labels.shape}\")\n",
        "    print(f\"   Unique labels: {torch.unique(labels)}\")\n",
        "    break\n",
        "\n",
        "print(\"âœ… First batch loaded\")\n",
        "# Print images.shape, labels.shape, torch.unique(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤” Reflection Prompts\n",
        "\n",
        "### Question 1: Why Shuffle Training Data?\n",
        "Imagine your training CSV is sorted: first 500 samples are Normal (0), next 500 are Tumor (1).\n",
        "\n",
        "**Scenario A:** `shuffle=False`\n",
        "- What pattern might the model learn in the first few batches?\n",
        "- Why is this a problem?\n",
        "\n",
        "**Scenario B:** `shuffle=True`\n",
        "- How does this fix the problem?\n",
        "\n",
        "**Your explanation:**\n",
        "> Without shuffling, the neural network would learn the order and start predicting based on sequence rather than actual features. This leads to overfitting because the model memorizes the data order instead of learning meaningful patterns.\n",
        ">\n",
        "> By shuffling, we create randomness so the neural network struggles to find order-based patterns. This forces it to learn actual features, preventing overfitting and improving generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 2: Batch Size Impact\n",
        "Compare these two setups:\n",
        "\n",
        "| Setup | Batch Size | Batches per Epoch | Updates per Epoch |\n",
        "|-------|------------|-------------------|-------------------|\n",
        "| A | 8 | 125 (1000/8) | 125 |\n",
        "| B | 32 | 32 (1000/32) | 32 |\n",
        "\n",
        "Assuming 1000 training samples:\n",
        "- Which setup makes **more gradient updates** per epoch?\n",
        "- Which setup is **faster** (fewer iterations)?\n",
        "- Which might **generalize better** (more noisy gradients)?\n",
        "\n",
        "**Your analysis:**\n",
        "> **Setup A (batch_size=8)** makes more gradient updates per epoch (125 vs 32).\n",
        "> **Setup B (batch_size=32)** is faster because it has fewer iterations.\n",
        "> **Setup A** generalizes better due to more frequent updates and noisier gradients, which helps prevent overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 3: num_workers Mystery\n",
        "The `num_workers` parameter controls parallel data loading.\n",
        "\n",
        "- `num_workers=0`: Data loads in main process (slower, but no issues)\n",
        "- `num_workers=4`: Data loads in 4 parallel workers (faster, but can cause bugs)\n",
        "\n",
        "When might you set `num_workers > 0`?  \n",
        "When might you stick with `num_workers=0`?\n",
        "\n",
        "**Your answer:**\n",
        "> **num_workers=0**: Use for small datasets where data loading is fast and you want to avoid any potential bugs or data mixing issues.\n",
        ">\n",
        "> **num_workers>0**: Use for large datasets where data loading becomes a bottleneck. More workers speed up loading but increase the likelihood of bugs or data corruption, especially with complex transforms.\n",
        "\n",
        "---\n",
        "d code blocks with MD? Ifd\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Next Steps\n",
        "\n",
        "Excellent! You've loaded training data with batching and shuffling.\n",
        "\n",
        "**Move to Notebook 03:** Val/Test Transforms (No Augmentation)\n",
        "\n",
        "**Key Takeaway:** Training DataLoader shuffles; validation/test do NOT!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
