{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧪 Notebook 03: Val/Test Transforms — No Augmentation\n",
        "\n",
        "**Purpose:** Build a deterministic transform pipeline for validation and test data (no random augmentations).\n",
        "\n",
        "**What you'll learn:** Why evaluation needs consistency, and how to ensure reproducible metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Concept Primer: Why NO Augmentation for Val/Test?\n",
        "\n",
        "### Training vs Evaluation: Different Goals\n",
        "\n",
        "**Training:**\n",
        "- Goal: Learn robust features that generalize\n",
        "- Strategy: Augment data to create synthetic variety\n",
        "- Random transforms: Flip, rotate, color jitter\n",
        "\n",
        "**Validation/Test:**\n",
        "- Goal: Measure performance consistently\n",
        "- Strategy: Apply only deterministic transforms\n",
        "- No randomness: Same image → same output every time\n",
        "\n",
        "### What Breaks Without This Rule?\n",
        "\n",
        "Imagine if validation used random augmentations:\n",
        "\n",
        "```python\n",
        "# Run 1: Validation accuracy = 85%\n",
        "# Run 2: Validation accuracy = 82%\n",
        "# Run 3: Validation accuracy = 87%\n",
        "```\n",
        "\n",
        "**Problem:** You can't trust the metrics! Accuracy changes due to randomness, not model improvement.\n",
        "\n",
        "### val_test_transform Pipeline\n",
        "\n",
        "```\n",
        "✅ CORRECT (Deterministic):\n",
        "Resize(96,96) → ToTensor() → Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "\n",
        "❌ WRONG (Has randomness):\n",
        "Resize → RandomHorizontalFlip → ToTensor → Normalize\n",
        "```\n",
        "\n",
        "**Key rule:** Normalization parameters **must match training** exactly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. ✅ Build `val_test_transform` with **only** deterministic transforms\n",
        "2. ✅ Use the **same** normalization as training (mean=std=0.5)\n",
        "3. ✅ Test transform on a sample image\n",
        "4. ✅ Verify output shape: `[3, 96, 96]`\n",
        "5. ✅ Understand why evaluation metrics require consistency\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ Acceptance Criteria\n",
        "\n",
        "Your val/test transform is correct when:\n",
        "\n",
        "- [ ] `val_test_transform` is a `transforms.Compose` object\n",
        "- [ ] It contains **only**: Resize, ToTensor, Normalize (no Random* transforms)\n",
        "- [ ] Normalization uses `mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]` (matching training)\n",
        "- [ ] Applying transform produces shape `[3, 96, 96]`\n",
        "- [ ] Running transform twice on the **same image** produces **identical** tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 💻 TODO 1: Import Required Libraries\n",
        "\n",
        "**What you need:**\n",
        "- `torchvision.transforms`\n",
        "- `PIL.Image`\n",
        "- `torch` (to test tensor equality)\n",
        "\n",
        "**Expected behavior:** Imports run without errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Imports successful\n"
          ]
        }
      ],
      "source": [
        "# TODO 1: Import libraries\n",
        "# Hint: from torchvision import transforms\n",
        "# Hint: from PIL import Image\n",
        "# Hint: import torch\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "print(\"✅ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 💻 TODO 2: Build val_test_transform (Deterministic Only!)\n",
        "\n",
        "**What you need to compose (in this order):**\n",
        "\n",
        "1. **`transforms.Resize((96, 96))`** — Ensure all images are 96×96\n",
        "2. **`transforms.ToTensor()`** — Convert PIL image → tensor [0,1]\n",
        "3. **`transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])`** — Normalize to [-1,1]\n",
        "\n",
        "**❗ DO NOT INCLUDE:**\n",
        "- ❌ RandomHorizontalFlip\n",
        "- ❌ RandomRotation\n",
        "- ❌ ColorJitter\n",
        "- ❌ Any Random* transforms\n",
        "\n",
        "**Expected output:** A `transforms.Compose` object stored in `val_test_transform`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ val_test_transform created:\n",
            "Compose(\n",
            "    Resize(size=(96, 96), interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TODO 2: Create val_test_transform (only deterministic transforms!)\n",
        "# Hint: val_test_transform = transforms.Compose([...])\n",
        "# Hint: Only include Resize, ToTensor, Normalize\n",
        "\n",
        "# YOUR CODE HERE\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "print(\"✅ val_test_transform created:\")\n",
        "print(val_test_transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 💻 TODO 3: Verify Determinism — Apply Transform Twice\n",
        "\n",
        "**What you need to do:**\n",
        "1. Load a sample image from `../data/pcam_images/`\n",
        "2. Apply `val_test_transform` **twice** to the same image\n",
        "3. Check if the two tensors are **exactly equal** using `torch.equal()`\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "✅ Transform applied twice\n",
        "   Tensor shapes match: True\n",
        "   Tensors are identical: True  (Deterministic!)\n",
        "```\n",
        "\n",
        "If `torch.equal()` returns `False`, you accidentally included a random transform!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Transform applied twice\n",
            "   Shape: torch.Size([3, 96, 96])\n",
            "   Results are identical: True\n"
          ]
        }
      ],
      "source": [
        "# TODO 3: Test determinism by applying transform twice\n",
        "# Hint: sample_img = Image.open('...')\n",
        "# Hint: transformed_1 = val_test_transform(sample_img)\n",
        "# Hint: transformed_2 = val_test_transform(sample_img)\n",
        "# Hint: torch.equal(transformed_1, transformed_2)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "sample_images = os.listdir('../data/pcam_images/')\n",
        "sample_path = os.path.join('../data/pcam_images/', sample_images[0])\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# Load image (we need to reload it for a fresh copy each time)\n",
        "sample_img_1 = Image.open(sample_path)\n",
        "sample_img_2 = Image.open(sample_path)\n",
        "\n",
        "# Apply transform to both copies\n",
        "transformed_1 = val_test_transform(sample_img_1)\n",
        "transformed_2 = val_test_transform(sample_img_2)\n",
        "\n",
        "# Check equality\n",
        "are_equal = torch.equal(transformed_1, transformed_2)\n",
        "\n",
        "print(\"✅ Transform applied twice\")\n",
        "print(f\"   Shape: {transformed_1.shape}\")\n",
        "print(f\"   Results are identical: {are_equal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🤔 Reflection Prompts\n",
        "\n",
        "### Question 1: What Breaks If Val/Test Had Random Augmentation?\n",
        "\n",
        "Imagine you're training a model and checking validation accuracy every epoch:\n",
        "\n",
        "**Scenario A: val_test_transform includes RandomHorizontalFlip**\n",
        "\n",
        "| Epoch | Val Accuracy |\n",
        "|-------|--------------|\n",
        "| 1 | 78% |\n",
        "| 2 | 82% |\n",
        "| 3 | 79% |\n",
        "| 4 | 85% |\n",
        "| 5 | 80% |\n",
        "\n",
        "**Questions:**\n",
        "- Did the model improve from Epoch 2 → 3?\n",
        "- Can you trust Epoch 4's 85% to select the best model?\n",
        "- What causes the fluctuations?\n",
        "\n",
        "**Your analysis:**\n",
        "> If validation/test had random augmentation, the results would be completely randomized and impossible to compare. From a computational point of view, you cannot validate or test because the model won't find consistent patterns. We need deterministic answers to check correctly. Unless you have a quantum computer, you cannot handle this level of randomness. What matters most is that it is deterministic - there should be nothing dependent on randomness, otherwise it's impossible to find meaningful results.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 2: Why Must Normalization Match Training?\n",
        "\n",
        "Consider this **incorrect** setup:\n",
        "```python\n",
        "# Training\n",
        "train_transform = Normalize(mean=[0.5]*3, std=[0.5]*3)  # [-1,1]\n",
        "\n",
        "# Val/Test (WRONG!)\n",
        "val_test_transform = Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
        "```\n",
        "\n",
        "**Question:** What happens when the model trained on [-1,1] data receives ImageNet-normalized inputs?\n",
        "\n",
        "**Your explanation:**\n",
        "> If the image is not normalized to the same scale, you'll have mismatched data distributions. One image might be completely black, another completely white, or whatever that means. If we normalize to different scales with different values, there's a mismatch in what should be the benchmarks. The normalization should be consistent across train/val/test - same scale, not different scales. This ensures the model receives data in the same format it was trained on.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 3: Deterministic vs Reproducible\n",
        "\n",
        "**Deterministic:** Same input → same output (no randomness)\n",
        "**Reproducible:** Same code → same result (controlled random seed)\n",
        "\n",
        "Which matters more for validation/test transforms? Why?\n",
        "\n",
        "**Your answer:**\n",
        "> Deterministic matters more for validation/test transforms. We need to ensure that the same input always produces the same output, with no randomness involved. This allows for consistent evaluation and fair comparison of model performance across different runs.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Next Steps\n",
        "\n",
        "Perfect! You've built a deterministic transform for evaluation.\n",
        "\n",
        "**Move to Notebook 04:** Load Val/Test DataLoaders\n",
        "\n",
        "**Key Takeaway:** Evaluation = Deterministic + No Shuffle!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
